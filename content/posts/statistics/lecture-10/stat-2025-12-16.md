---
title: "LECTURE 10: Correlation and Regression"
date: 2025-12-16T11:15:00+02:00
deadline:
categories: [Statistics]
draft: false
---
#### Summary:

Correlation analysis and linear prediction serve as fundamental statistical procedures used to examine relationships between variables and estimate outcomes. A correlation describes the association between two equal-interval numeric variables, where the pattern of scores can be visualized using a scatter diagram. In these diagrams, the predictor variable ($X$) is placed on the horizontal axis and the criterion variable ($Y$) on the vertical axis. Patterns of association are characterized by their direction—positive or negative—and their strength, ranging from weak to perfect. While linear correlations approximate a straight line, curvilinear relationships follow systematic non-linear patterns.

The Pearson correlation coefficient ($r$) quantifies this relationship by averaging the cross-products of standardized Z scores, ranging from -1 to +1. Statistical significance is determined via a t-test to assess if the relationship likely exists in the general population. However, correlation does not imply causality, as a third variable may influence both factors, or the direction of effect may be reversed. Factors such as restriction in range, outliers, and unreliability of measurement can underestimate or distort the true correlation.

Linear prediction, or regression, utilizes these associations to forecast scores on a criterion variable. The linear prediction rule follows the formula $\hat{Y} =a+(b)(X)$, where a represents the regression constant (intercept) and b is the regression coefficient (slope). The best-fitting regression line is determined by the least squares criterion, which minimizes the sum of squared errors between predicted and actual scores. In research, unstandardized coefficients are often converted to standardized regression coefficients ($\beta$) to allow for comparison across different scales. Multiple regression further improves accuracy by incorporating two or more predictor variables into a single model. These procedures rely on assumptions of normality, linearity, homoscedasticity, and independence to ensure valid results.

#### Reading materials:

##### Mandatory:

* Aron, A., Coups, E. J., & Aron, E. N. (2013). *Statistics for psychology* (6th ed.). Pearson. ({{< a_blank title="DOWNLOAD PDF" url="https://ibuit-my.sharepoint.com/:b:/g/personal/kirjakovski_ibu_edu_mk/EY8YX1R78ChDqORSuUCMc-0Bbr8wv638kogwUcTQUzSATQ?e=gCJH5O" >}})

	* Correlation [Chapter 11]
	* Prediction [Chapter 12]

##### Supplementary:

* Howitt, D., & Cramer, D. (2014). *Introduction to statistics in psychology: With SPSS* (6th Edition). Pearson. ({{< a_blank title="DOWNLOAD PDF" url="https://ibuit-my.sharepoint.com/:b:/g/personal/kirjakovski_ibu_edu_mk/EVK61aTc5F9Justfth_5xPYBdWjXT3R5JRjz8ha3Smc1aw?e=VKmqI3" >}})

	* Correlation Coefficients: Pearson Correlation and Spearman’s rho [Chapter 8]
	* Regression: Prediction with Precision [Chapter 9]