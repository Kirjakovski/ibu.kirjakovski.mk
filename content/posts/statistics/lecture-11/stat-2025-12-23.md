---
title: "LECTURE 11: Chi-Square Tests and Nonparametric Statistics"
date: 2025-12-23T11:15:00+02:00
deadline:
categories: [Statistics]
draft: false
---
#### Summary:

Chi-square tests serve as hypothesis-testing procedures specifically designed for nominal or categorical variables, where measurements represent frequencies within distinct categories. The chi-square test for goodness of fit examines how an observed frequency distribution of a single nominal variable aligns with an expected pattern based on the null hypothesis. In contrast, the chi-square test for independence evaluates whether a relationship exists between two nominal variables organized in a contingency table. The calculation involves summing the squared differences between observed and expected frequencies, divided by the expected frequencies. Key parameters include degrees of freedom, which depend on the number of categories or cells, and cutoff scores determined by significance levels.

Statistical power in chi-square tests is influenced by sample size and degrees of freedom, while effect size is measured using the phi coefficient for $2 \times 2$ tables or Cramer’s phi for larger designs. A fundamental assumption is the independence of observations, meaning scores cannot be related or based on repeated testing of the same individuals.

When data violates the parametric assumptions of normality and equal variances, researchers employ nonparametric or distribution-free statistics. One approach is data transformation, applying mathematical procedures like square-root, log, or inverse transformations to correct for skewness and approximate a normal distribution. Alternatively, rank-order tests transform raw scores into ranks, resulting in a rectangular or uniform distribution. Major nonparametric tests include the Wilcoxon signed-rank test for dependent means, the Wilcoxon rank-sum or Mann-Whitney U test for independent means, the Kruskal-Wallis test for analysis of variance, and Spearman’s rho for correlation. These tests typically compare medians rather than means. Advanced computer-intensive methods, such as randomization tests and bootstrap tests, provide additional frameworks for hypothesis testing through repeated computations and data reorganization to determine the likelihood of observed outcomes occurring by chance.

#### Reading materials:

##### Mandatory:

* Aron, A., Coups, E. J., & Aron, E. N. (2013). *Statistics for psychology* (6th ed.). Pearson. ({{< a_blank title="DOWNLOAD PDF" url="https://ibuit-my.sharepoint.com/:b:/g/personal/kirjakovski_ibu_edu_mk/EY8YX1R78ChDqORSuUCMc-0Bbr8wv638kogwUcTQUzSATQ?e=gCJH5O" >}})

	* Chi-Square Tests [Chapter 13]
	* Strategies When Population Distributions Are Not Normal: Data Transformations and Rank-Order Tests [Chapter 14]

##### Supplementary:

* Howitt, D., & Cramer, D. (2014). *Introduction to statistics in psychology: With SPSS* (6th Edition). Pearson. ({{< a_blank title="DOWNLOAD PDF" url="https://ibuit-my.sharepoint.com/:b:/g/personal/kirjakovski_ibu_edu_mk/EVK61aTc5F9Justfth_5xPYBdWjXT3R5JRjz8ha3Smc1aw?e=VKmqI3" >}})

	* Chi-Square: Differences Between Samples of Frequency Data [Chapter 15]
	* Ranking Tests: Nonparametric Statistics [Chapter 19]