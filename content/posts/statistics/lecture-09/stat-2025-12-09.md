---
title: "LECTURE 9: Introduction to the ANOVA"
date: 2025-12-09T11:15:00+02:00
deadline:
categories: [Statistics]
draft: false
---
#### Summary:

Analysis of Variance (ANOVA) is a statistical procedure utilized to test for variations among the means of three or more independent groups. While a t-test is sufficient for comparing two groups, ANOVA is designed to handle the complexity of multiple groups across a single dimension, known as one-way ANOVA. The core logic of the procedure involves comparing two different estimates of population variance: the within-groups estimate and the between-groups estimate.

The within-groups estimate, or mean square within, reflects variation caused solely by chance factors, such as individual differences or measurement error. It remains unaffected by whether the research hypothesis is true. Conversely, the between-groups estimate reflects both chance variation and the treatment effect. When the null hypothesis is true—meaning population means are equal—these two estimates should be approximately equal, resulting in an F ratio near 1. If the research hypothesis is true and a treatment effect exists, the between-groups estimate becomes significantly larger than the within-groups estimate, producing an F ratio greater than 1.

Carrying out an ANOVA requires calculating the F ratio and comparing it against a cutoff score from an F distribution table, determined by the numerator and denominator degrees of freedom. Statistical assumptions for the test include normality, homogeneity of variance, and independence of scores. In instances where the null hypothesis is rejected, the omnibus F test indicates a difference exists but does not specify which groups differ. Researchers may then employ planned contrasts to investigate specific, a priori comparisons or post hoc tests, such as the Bonferroni procedure or Scheffé test, for exploratory analysis. Effect size is typically measured using R-squared or eta-squared, representing the proportion of total variation accounted for by the differences between group means. This comprehensive framework allows for the systematic evaluation of differences across multiple population parameters.

#### Reading materials:

##### Mandatory:

* Aron, A., Coups, E. J., & Aron, E. N. (2013). *Statistics for psychology* (6th ed.). Pearson. ({{< a_blank title="DOWNLOAD PDF" url="https://ibuit-my.sharepoint.com/:b:/g/personal/kirjakovski_ibu_edu_mk/EY8YX1R78ChDqORSuUCMc-0Bbr8wv638kogwUcTQUzSATQ?e=gCJH5O" >}})

	* Introduction to the Analysis of Variance [Chapter 9]
	* Factorial Analysis of Variance (OPTIONAL) [Chapter 10]

##### Supplementary:

* Howitt, D., & Cramer, D. (2014). *Introduction to statistics in psychology: With SPSS* (6th Edition). Pearson. ({{< a_blank title="DOWNLOAD PDF" url="https://ibuit-my.sharepoint.com/:b:/g/personal/kirjakovski_ibu_edu_mk/EVK61aTc5F9Justfth_5xPYBdWjXT3R5JRjz8ha3Smc1aw?e=VKmqI3" >}})

	* The Variance Ratio Test: The F-Ratio to Compare Two Variances [Chapter 20]
	* Analysis of Variance (ANOVA): Introduction to the One-Way Unrelated or Uncorrelated ANOVA [Chapter 21]
	* Two-Way Analysis of Variance for Unrelated/ Uncorrelated Scores: Two Studies for the Price of One? [Chapter 23]
	* Multiple Comparisons in ANOVA: Just Where Do the Differences Lie? [Chapter 24]