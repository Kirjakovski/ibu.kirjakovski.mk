---
title: "LECTURE 2: Working with Data"
date: 2025-10-27T16:49:12+02:00
deadline:
categories: [Advanced Quantitative Research Methods]
draft: false
---
#### Summary:

This lecture covers the fundamental aspects of working with quantitative data in research. It begins by exploring Data Theory, defining data not just as raw facts or numbers but as information collected for examination. Data isn't merely "given" (datum) but actively "taken" (capta), shaped by the ideas, technologies, and contexts involved in its production. This Non-Neutrality Principle highlights that data are socio-technical constructs, never truly raw or objective.

Data can be classified in various ways: discrete (countable) vs. continuous (measurable); small vs. big data (characterized by Volume, Velocity, Variety); structured, semi-structured, or unstructured. Data originates from different sources (captured, exhaust, derived) and can be primary (collected by the researcher) or secondary (collected by others). The DIKW framework illustrates the progression from raw Data to Information (organized), Knowledge (understood patterns), and Wisdom (applied understanding).

Data Collection in psychology utilizes several methods. Self-reports gather internal states via questionnaires (e.g., Likert scales). Behavioral/Observational measures record actions (e.g., frequency, duration, latency) or their physical traces. Physiological measures objectively record bodily responses like brain activity (EEG, fMRI), autonomic nervous system activity (heart rate, skin conductance), or biochemical levels (hormones). Archival data involves analyzing existing records.

Because studying entire populations is impractical, researchers use sampling. Key concepts include the population, sample, sampling frame, and generalizability. Sampling error (chance differences) and bias (systematic differences) are central concerns. Probability sampling (e.g., Simple Random, Stratified, Cluster) gives each member a known selection chance, vital for population description. Nonprobability sampling (e.g., Convenience, Purposive, Quota, Snowball) is common in hypothesis testing but limits generalizability.

Data Management involves systematic administration from collection to analysis. This includes data entry, cleaning (checking for impossible or inconsistent codes), dealing with outliers, coding (assigning numerical values, documented in a codebook), potential data transformation, and secure storage. Ethical standards mandate data integrity (avoiding fabrication, falsification, plagiarism), confidentiality, participant privacy, and responsible data sharing for verification, aligning with Open Science principles.